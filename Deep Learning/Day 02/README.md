- Slope is not constant when the line is not linear. 

Many complex equations are not suitable solve using linear equations.
Activation functions help build non-linear equations.

For hidden layers, if you're not sure which activation function should use just use ReLU as default choice. ReLU is fast, and it doesn't have any problems like vanishing gradients. 


## Binary classification using Neural Network

Suppose we have a (n x n) image. The RGB matrix is a 3 dimensional array. We have to convert the RGB matrix into a single dimensional array.  

## Perceptron

