{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5eCKz3899iEP"
      },
      "source": [
        "## Lemmatization\n",
        "\n",
        "This technique usually retrieves the root word of a given word."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "bcR17_GkK6UJ"
      },
      "outputs": [],
      "source": [
        "import nltk\n",
        "from nltk.corpus import wordnet\n",
        "import spacy"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZcyuWJGHwnql",
        "outputId": "6441464e-123a-41b8-8db9-de32c6763b5e"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package wordnet to /root/nltk_data...\n",
            "[nltk_data] Downloading package averaged_perceptron_tagger to\n",
            "[nltk_data]     /root/nltk_data...\n",
            "[nltk_data]   Unzipping taggers/averaged_perceptron_tagger.zip.\n",
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Unzipping tokenizers/punkt.zip.\n",
            "[nltk_data] Downloading package omw-1.4 to /root/nltk_data...\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 3
        }
      ],
      "source": [
        "nltk.download('wordnet')\n",
        "nltk.download('averaged_perceptron_tagger')\n",
        "nltk.download('punkt')\n",
        "nltk.download('omw-1.4')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "x-ToZ0vlMoOc"
      },
      "source": [
        "### Lemmatization using SpaCy"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5Z0zmFrKMfa9",
        "outputId": "3c170392-fc6a-4f03-8ca5-332406d5a871"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "eating => eat\n",
            "etas => eta\n",
            "eta => eta\n",
            "ate => eat\n",
            "adjustable => adjustable\n",
            "rafting => raft\n",
            "ability => ability\n",
            "meeting => meeting\n",
            "better => well\n"
          ]
        }
      ],
      "source": [
        "nlp = spacy.load(\"en_core_web_sm\")\n",
        "doc = nlp(\"eating etas eta ate adjustable rafting ability meeting better\")\n",
        "\n",
        "for token in doc:\n",
        "    print(f\"{token} => {token.lemma_}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hawoeqlAvrY4"
      },
      "source": [
        "## Lemmatization using NLTK `WordNetLemmatizer`"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "oZtswuztaaos"
      },
      "outputs": [],
      "source": [
        "from nltk.stem import WordNetLemmatizer\n",
        "from nltk import pos_tag"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "hpNq5NMMwLex"
      },
      "outputs": [],
      "source": [
        "lemmatizer = WordNetLemmatizer()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4M3Vhqu7yPoI"
      },
      "source": [
        "The **lemmatize** method takes two arguments these are the word itself and the POS tags  \n",
        "\n",
        "<ins>**POS tags**</ins>\n",
        "\n",
        "Noun => n    \n",
        "Verb => v  \n",
        "Adjective => a  \n",
        "Adverb => r  "
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "words = [\"goes\", \"fairly\", \"sportingly\", \"eating\", \"eats\", \"eaten\", \"writing\", \"programming\", \"programs\", \"finally\", \"history\"]"
      ],
      "metadata": {
        "id": "A1jrK2CTVXAr"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for word in words:\n",
        "  print(f\"{word} => {lemmatizer.lemmatize(word, pos='v')}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5XW1lR59VnKz",
        "outputId": "a5895ae3-bc0b-4edf-f10a-2832cf95d65b"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "goes => go\n",
            "fairly => fairly\n",
            "sportingly => sportingly\n",
            "eating => eat\n",
            "eats => eat\n",
            "eaten => eat\n",
            "writing => write\n",
            "programming => program\n",
            "programs => program\n",
            "finally => finally\n",
            "history => history\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "m5wqPB-Vxa3y",
        "outputId": "ce49f12d-9973-4b41-8f62-70d6882f168d"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "eating: [('eating', 'VBG')]\n",
            "Lemmatized form of eating: eat\n",
            "ate: [('ate', 'NN')]\n",
            "Lemmatized form of ate: ate\n",
            "faulting: [('faulting', 'VBG')]\n",
            "Lemmatized form of faulting: fault\n",
            "rigorous: [('rigorous', 'JJ')]\n",
            "Lemmatized form of rigorous: rigorous\n",
            "Programs: [('Programs', 'NNS')]\n",
            "Lemmatized form of Programs: Programs\n",
            "Subodh: [('Subodh', 'NN')]\n",
            "Lemmatized form of Subodh: Subodh\n"
          ]
        }
      ],
      "source": [
        "# Function to map POS tags to WordNet POS tags\n",
        "def get_wordnet_pos(treebank_tag):\n",
        "    if treebank_tag.startswith('J'):\n",
        "        return wordnet.ADJ\n",
        "    elif treebank_tag.startswith('V'):\n",
        "        return wordnet.VERB\n",
        "    elif treebank_tag.startswith('N'):\n",
        "        return wordnet.NOUN\n",
        "    elif treebank_tag.startswith('R'):\n",
        "        return wordnet.ADV\n",
        "    else:\n",
        "        return None\n",
        "\n",
        "# List of words\n",
        "words = [\"eating\", \"ate\", 'faulting', \"rigorous\" ,'Programs', 'Subodh']\n",
        "\n",
        "# Process each word\n",
        "for word in words:\n",
        "    pos_type = pos_tag([word])\n",
        "    print(f\"{word}: {pos_type}\")\n",
        "\n",
        "    # Extract POS label\n",
        "    pos_label = pos_type[0][1]\n",
        "\n",
        "    # Convert the Penn Treebank tag to a WordNet tag\n",
        "    wordnet_pos = get_wordnet_pos(pos_label)\n",
        "\n",
        "    # Lemmatize only if the tag is a valid WordNet POS tag\n",
        "    if wordnet_pos:\n",
        "        lemma = lemmatizer.lemmatize(word, pos=wordnet_pos)\n",
        "        print(f\"Lemmatized form of {word}: {lemma}\")\n",
        "    else:\n",
        "        print(f\"No lemmatization for {word}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Performance: Lemmatization vs Stemming\n",
        "Although, Lemmatization can accurately predict the root but since it uses more complex rules and also that it uses a dictionary to maintain all the possible relation between an input word, it take more time to proceed the result."
      ],
      "metadata": {
        "id": "hNzI1LB8XIXq"
      }
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "collapsed_sections": [
        "x-ToZ0vlMoOc"
      ],
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python",
      "version": "3.11.5"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}